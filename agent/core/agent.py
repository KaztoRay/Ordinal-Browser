"""
ë³´ì•ˆ ì—ì´ì „íŠ¸ ì½”ì–´ ëª¨ë“ˆ
======================

ë¹„ë™ê¸° ìœ„í˜‘ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ SecurityAgent í´ë˜ìŠ¤.
ëª¨ë“  ë¶„ì„ê¸°ë¥¼ ì¡°ìœ¨í•˜ê³ , LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í†µí•´
URL/ìŠ¤í¬ë¦½íŠ¸/í˜ì´ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ThreatReportë¥¼ ìƒì„±í•˜ë©°, ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import asyncio
import hashlib
import logging
import time
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from typing import Any, Optional

from agent.core.config import AgentConfig

logger = logging.getLogger(__name__)


# ============================================================
# ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
# ============================================================

class ThreatLevel(IntEnum):
    """ìœ„í˜‘ ìˆ˜ì¤€ (protoì™€ ë™ê¸°í™”)"""
    SAFE = 0
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4


class ThreatType(str, Enum):
    """ìœ„í˜‘ ìœ í˜•"""
    PHISHING = "phishing"
    MALWARE = "malware"
    XSS = "xss"
    PRIVACY = "privacy"
    CERT = "cert"


@dataclass
class ThreatDetail:
    """ê°œë³„ ìœ„í˜‘ ìƒì„¸ ì •ë³´"""
    threat_type: ThreatType
    threat_level: ThreatLevel
    confidence: float  # 0.0 ~ 1.0
    description: str
    indicators: list[str] = field(default_factory=list)
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass
class ThreatReport:
    """í†µí•© ìœ„í˜‘ ë³´ê³ ì„œ"""
    url: str
    overall_level: ThreatLevel = ThreatLevel.SAFE
    overall_score: float = 0.0  # 0.0 (ì•ˆì „) ~ 1.0 (ìœ„í—˜)
    details: list[ThreatDetail] = field(default_factory=list)
    recommendations: list[str] = field(default_factory=list)
    analysis_time_ms: float = 0.0
    cached: bool = False
    timestamp: float = field(default_factory=time.time)

    def add_detail(self, detail: ThreatDetail) -> None:
        """ìœ„í˜‘ ìƒì„¸ ì •ë³´ ì¶”ê°€ ë° ì „ì²´ ì ìˆ˜ ì¬ê³„ì‚°"""
        self.details.append(detail)
        self._recalculate()

    def _recalculate(self) -> None:
        """ì „ì²´ ìœ„í˜‘ ìˆ˜ì¤€ê³¼ ì ìˆ˜ë¥¼ ì¬ê³„ì‚°"""
        if not self.details:
            self.overall_level = ThreatLevel.SAFE
            self.overall_score = 0.0
            return
        # ê°€ì¥ ë†’ì€ ìœ„í˜‘ ìˆ˜ì¤€ ì„ íƒ
        self.overall_level = max(d.threat_level for d in self.details)
        # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚° (ë†’ì€ ì‹ ë¢°ë„ì— ë” í° ê°€ì¤‘ì¹˜)
        total_weight = sum(d.confidence for d in self.details)
        if total_weight > 0:
            weighted_sum = sum(
                d.confidence * (d.threat_level / ThreatLevel.CRITICAL)
                for d in self.details
            )
            self.overall_score = min(1.0, weighted_sum / total_weight)
        else:
            self.overall_score = 0.0


# ============================================================
# LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# ============================================================

class PromptTemplates:
    """LLM ë¶„ì„ìš© ì‹œìŠ¤í…œ/ìœ ì € í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""

    # ---- URL ë¶„ì„ í”„ë¡¬í”„íŠ¸ ----
    URL_SYSTEM_PROMPT: str = (
        "ë‹¹ì‹ ì€ ì›¹ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. URLì„ ë¶„ì„í•˜ì—¬ í”¼ì‹±, ì•…ì„±ì½”ë“œ, "
        "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ì„ íƒì§€í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\n"
        "ì‘ë‹µ í˜•ì‹:\n"
        "{\n"
        '  "threat_level": "SAFE|LOW|MEDIUM|HIGH|CRITICAL",\n'
        '  "threat_types": ["phishing", "malware", ...],\n'
        '  "confidence": 0.0~1.0,\n'
        '  "reasoning": "ë¶„ì„ ê·¼ê±°",\n'
        '  "indicators": ["ì§€í‘œ1", "ì§€í‘œ2"],\n'
        '  "recommendation": "ê¶Œì¥ ì¡°ì¹˜"\n'
        "}"
    )

    URL_USER_PROMPT: str = (
        "ë‹¤ìŒ URLì˜ ë³´ì•ˆ ìœ„í˜‘ì„ ë¶„ì„í•˜ì„¸ìš”:\n\n"
        "URL: {url}\n"
        "ë„ë©”ì¸: {domain}\n"
        "ì„œë¸Œë„ë©”ì¸ ìˆ˜: {subdomain_count}\n"
        "URL ê¸¸ì´: {url_length}\n"
        "íŠ¹ìˆ˜ ë¬¸ì ë¹„ìœ¨: {special_char_ratio:.2f}\n"
        "IP ì£¼ì†Œ ì‚¬ìš© ì—¬ë¶€: {uses_ip}\n"
        "HTTPS ì—¬ë¶€: {is_https}\n"
        "URL ì—”íŠ¸ë¡œí”¼: {entropy:.2f}\n\n"
        "ì´ URLì´ í”¼ì‹±ì´ë‚˜ ì•…ì„± ì‚¬ì´íŠ¸ì¼ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ì„¸ìš”."
    )

    # ---- ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ----
    SCRIPT_SYSTEM_PROMPT: str = (
        "ë‹¹ì‹ ì€ JavaScript ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì½”ë“œì—ì„œ "
        "ì•…ì„± íŒ¨í„´, ë‚œë…í™”, ë°ì´í„° ìœ ì¶œ, í¬ë¦½í† ë§ˆì´ë‹ ë“±ì„ íƒì§€í•©ë‹ˆë‹¤.\n"
        "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\n"
        "ì‘ë‹µ í˜•ì‹:\n"
        "{\n"
        '  "threat_level": "SAFE|LOW|MEDIUM|HIGH|CRITICAL",\n'
        '  "malware_type": "none|obfuscation|data_exfil|crypto_miner|exploit",\n'
        '  "confidence": 0.0~1.0,\n'
        '  "reasoning": "chain-of-thought ë¶„ì„",\n'
        '  "suspicious_patterns": ["íŒ¨í„´1", "íŒ¨í„´2"],\n'
        '  "behavior_prediction": "ì˜ˆì¸¡ë˜ëŠ” ë™ì‘"\n'
        "}"
    )

    SCRIPT_USER_PROMPT: str = (
        "ë‹¤ìŒ JavaScript ì½”ë“œì˜ ë³´ì•ˆ ìœ„í˜‘ì„ ë¶„ì„í•˜ì„¸ìš”:\n\n"
        "```javascript\n{code}\n```\n\n"
        "ì½”ë“œ í†µê³„:\n"
        "- eval() ì‚¬ìš© íšŸìˆ˜: {eval_count}\n"
        "- document.write() ì‚¬ìš© íšŸìˆ˜: {doc_write_count}\n"
        "- ì¸ì½”ë”©ëœ ë¬¸ìì—´ ìˆ˜: {encoded_string_count}\n"
        "- ë³€ìˆ˜ëª… ì—”íŠ¸ë¡œí”¼: {var_entropy:.2f}\n"
        "- ë‚œë…í™” ì ìˆ˜: {obfuscation_score:.2f}\n\n"
        "ì´ ì½”ë“œê°€ ì•…ì„±ì¸ì§€ ë¶„ì„í•˜ì„¸ìš”. chain-of-thoughtë¡œ ì¶”ë¡ í•˜ì„¸ìš”."
    )

    # ---- í˜ì´ì§€ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ----
    PAGE_SYSTEM_PROMPT: str = (
        "ë‹¹ì‹ ì€ ì›¹ í˜ì´ì§€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
        "HTML ì½˜í…ì¸ ì™€ URLì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ "
        "í”¼ì‹±, XSS, ì•…ì„±ì½”ë“œ, í”„ë¼ì´ë²„ì‹œ ì¹¨í•´ë¥¼ íƒì§€í•©ë‹ˆë‹¤.\n"
        "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\n"
        "ì‘ë‹µ í˜•ì‹:\n"
        "{\n"
        '  "overall_threat_level": "SAFE|LOW|MEDIUM|HIGH|CRITICAL",\n'
        '  "threats": [\n'
        "    {\n"
        '      "type": "phishing|malware|xss|privacy",\n'
        '      "level": "SAFE|LOW|MEDIUM|HIGH|CRITICAL",\n'
        '      "confidence": 0.0~1.0,\n'
        '      "description": "ì„¤ëª…"\n'
        "    }\n"
        "  ],\n"
        '  "security_score": 0~100,\n'
        '  "recommendations": ["ê¶Œì¥1", "ê¶Œì¥2"]\n'
        "}"
    )

    PAGE_USER_PROMPT: str = (
        "ë‹¤ìŒ ì›¹ í˜ì´ì§€ì˜ ë³´ì•ˆì„ ì¢…í•© ë¶„ì„í•˜ì„¸ìš”:\n\n"
        "URL: {url}\n"
        "í˜ì´ì§€ ì œëª©: {title}\n\n"
        "HTML ìš”ì•½:\n"
        "- í¼ ìˆ˜: {form_count}\n"
        "- ë¹„ë°€ë²ˆí˜¸ í•„ë“œ ìˆ˜: {password_field_count}\n"
        "- ì™¸ë¶€ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜: {external_script_count}\n"
        "- ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë¹„ìœ¨: {external_resource_ratio:.2f}\n"
        "- iframe ìˆ˜: {iframe_count}\n"
        "- ìˆ¨ê²¨ì§„ ìš”ì†Œ ìˆ˜: {hidden_element_count}\n\n"
        "HTML ë°œì·Œ (ì²« 2000ì):\n"
        "```html\n{html_snippet}\n```\n\n"
        "ì¢…í•©ì ì¸ ë³´ì•ˆ ìœ„í˜‘ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
    )


# ============================================================
# ìºì‹œ í•­ëª©
# ============================================================

@dataclass
class _CacheEntry:
    """ë¶„ì„ ê²°ê³¼ ìºì‹œ í•­ëª©"""
    report: ThreatReport
    created_at: float
    ttl: float

    @property
    def is_expired(self) -> bool:
        return (time.time() - self.created_at) > self.ttl


# ============================================================
# SecurityAgent ë©”ì¸ í´ë˜ìŠ¤
# ============================================================

class SecurityAgent:
    """
    ë¹„ë™ê¸° ë³´ì•ˆ ë¶„ì„ ì—ì´ì „íŠ¸

    ëª¨ë“  ë¶„ì„ê¸°(PhishingAnalyzer, MalwareAnalyzer, PrivacyAnalyzer)ë¥¼
    ì¡°ìœ¨í•˜ì—¬ URL, ìŠ¤í¬ë¦½íŠ¸, í˜ì´ì§€ì— ëŒ€í•œ í†µí•© ìœ„í˜‘ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    LLM ì¶”ë¡ , ê²°ê³¼ ìºì‹±, ë³‘ë ¬ ë¶„ì„ì„ ì§€ì›í•©ë‹ˆë‹¤.
    """

    def __init__(self, config: Optional[AgentConfig] = None) -> None:
        """
        ë³´ì•ˆ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”

        Args:
            config: ì—ì´ì „íŠ¸ ì„¤ì •. Noneì´ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©.
        """
        self.config = config or AgentConfig()
        self._cache: dict[str, _CacheEntry] = {}
        self._cache_lock = asyncio.Lock()
        self._initialized = False

        # ë¶„ì„ê¸°ëŠ” ì§€ì—° ì´ˆê¸°í™” (import ìˆœí™˜ ë°©ì§€)
        self._phishing_analyzer: Any = None
        self._malware_analyzer: Any = None
        self._privacy_analyzer: Any = None
        self._llm_inference: Any = None

        logger.info("SecurityAgent ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (v%s)", self.config.version)

    async def initialize(self) -> None:
        """
        ì—ì´ì „íŠ¸ ë° ëª¨ë“  ë¶„ì„ê¸° ì´ˆê¸°í™”

        ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , LLM ì¶”ë¡  ì—”ì§„ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
        """
        if self._initialized:
            logger.warning("SecurityAgentê°€ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return

        logger.info("SecurityAgent ì´ˆê¸°í™” ì‹œì‘...")

        # ë¶„ì„ê¸° ì§€ì—° ì„í¬íŠ¸ ë° ì´ˆê¸°í™”
        from agent.analyzers.phishing_analyzer import PhishingAnalyzer
        from agent.analyzers.malware_analyzer import MalwareAnalyzer
        from agent.analyzers.privacy_analyzer import PrivacyAnalyzer

        self._phishing_analyzer = PhishingAnalyzer(self.config)
        self._malware_analyzer = MalwareAnalyzer(self.config)
        self._privacy_analyzer = PrivacyAnalyzer(self.config)

        # LLM ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” (ì„ íƒì )
        try:
            from agent.models.inference import LLMInference
            self._llm_inference = LLMInference(self.config.llm)
            logger.info("LLM ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError:
            logger.warning("LLM ì¶”ë¡  ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ë¶„ì„ ë¹„í™œì„±í™”.")
        except Exception as e:
            logger.warning("LLM ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: %s", e)

        self._initialized = True
        logger.info("SecurityAgent ì´ˆê¸°í™” ì™„ë£Œ")

    async def shutdown(self) -> None:
        """ì—ì´ì „íŠ¸ ì¢…ë£Œ ë° ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        logger.info("SecurityAgent ì¢…ë£Œ ì¤‘...")
        self._cache.clear()
        self._initialized = False
        logger.info("SecurityAgent ì¢…ë£Œ ì™„ë£Œ")

    # ============================
    # URL ë¶„ì„
    # ============================

    async def analyze_url(self, url: str, use_llm: bool = True) -> ThreatReport:
        """
        URL ë³´ì•ˆ ë¶„ì„

        í”¼ì‹± ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ URLì˜ ìœ„í˜‘ ìˆ˜ì¤€ì„ í‰ê°€í•©ë‹ˆë‹¤.
        ìºì‹œëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            url: ë¶„ì„í•  URL
            use_llm: LLM ì‹¬ì¸µ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ThreatReport: ìœ„í˜‘ ë³´ê³ ì„œ
        """
        self._ensure_initialized()

        # ìºì‹œ í™•ì¸
        cache_key = self._make_cache_key("url", url)
        cached = await self._get_cached(cache_key)
        if cached is not None:
            return cached

        start_time = time.monotonic()
        report = ThreatReport(url=url)

        # í”¼ì‹± ë¶„ì„ê¸° ì‹¤í–‰
        phishing_detail = await self._phishing_analyzer.analyze_url(url)
        if phishing_detail is not None:
            report.add_detail(phishing_detail)

        # LLM ì‹¬ì¸µ ë¶„ì„ (ì„ íƒì )
        if use_llm and self._llm_inference is not None:
            llm_detail = await self._analyze_url_with_llm(url)
            if llm_detail is not None:
                report.add_detail(llm_detail)

        # ê¶Œì¥ ì‚¬í•­ ìƒì„±
        report.recommendations = self._generate_recommendations(report)
        report.analysis_time_ms = (time.monotonic() - start_time) * 1000

        # ìºì‹œ ì €ì¥
        await self._set_cached(cache_key, report)

        logger.info(
            "URL ë¶„ì„ ì™„ë£Œ: %s â†’ %s (%.1fms)",
            url, report.overall_level.name, report.analysis_time_ms
        )
        return report

    # ============================
    # ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„
    # ============================

    async def analyze_script(self, code: str, source_url: str = "") -> ThreatReport:
        """
        JavaScript ì½”ë“œ ë³´ì•ˆ ë¶„ì„

        ì•…ì„± íŒ¨í„´, ë‚œë…í™”, ë°ì´í„° ìœ ì¶œ ê°€ëŠ¥ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.

        Args:
            code: JavaScript ì†ŒìŠ¤ ì½”ë“œ
            source_url: ìŠ¤í¬ë¦½íŠ¸ ì¶œì²˜ URL

        Returns:
            ThreatReport: ìœ„í˜‘ ë³´ê³ ì„œ
        """
        self._ensure_initialized()

        # ìºì‹œ í™•ì¸ (ì½”ë“œ í•´ì‹œ ê¸°ë°˜)
        code_hash = hashlib.sha256(code.encode()).hexdigest()[:16]
        cache_key = self._make_cache_key("script", code_hash)
        cached = await self._get_cached(cache_key)
        if cached is not None:
            return cached

        start_time = time.monotonic()
        report = ThreatReport(url=source_url or f"script:{code_hash}")

        # ì•…ì„±ì½”ë“œ ë¶„ì„ê¸° ì‹¤í–‰
        malware_detail = await self._malware_analyzer.analyze_script(code)
        if malware_detail is not None:
            report.add_detail(malware_detail)

        # LLM ì‹¬ì¸µ ë¶„ì„ (ì„ íƒì )
        if self._llm_inference is not None and len(code) <= 10000:
            llm_detail = await self._analyze_script_with_llm(code)
            if llm_detail is not None:
                report.add_detail(llm_detail)

        report.recommendations = self._generate_recommendations(report)
        report.analysis_time_ms = (time.monotonic() - start_time) * 1000

        await self._set_cached(cache_key, report)

        logger.info(
            "ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ ì™„ë£Œ: %s â†’ %s (%.1fms)",
            report.url, report.overall_level.name, report.analysis_time_ms
        )
        return report

    # ============================
    # í˜ì´ì§€ ì¢…í•© ë¶„ì„
    # ============================

    async def analyze_page(
        self,
        url: str,
        html_content: str,
        use_llm: bool = True,
    ) -> ThreatReport:
        """
        ì›¹ í˜ì´ì§€ ì¢…í•© ë³´ì•ˆ ë¶„ì„

        URL, HTML ì½˜í…ì¸ , ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë™ì‹œì— ë¶„ì„í•˜ì—¬
        í†µí•© ìœ„í˜‘ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            url: í˜ì´ì§€ URL
            html_content: HTML ì†ŒìŠ¤ ì½”ë“œ
            use_llm: LLM ì‹¬ì¸µ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ThreatReport: í†µí•© ìœ„í˜‘ ë³´ê³ ì„œ
        """
        self._ensure_initialized()

        # ìºì‹œ í™•ì¸
        content_hash = hashlib.sha256(
            f"{url}:{html_content[:1000]}".encode()
        ).hexdigest()[:16]
        cache_key = self._make_cache_key("page", content_hash)
        cached = await self._get_cached(cache_key)
        if cached is not None:
            return cached

        start_time = time.monotonic()
        report = ThreatReport(url=url)

        # ëª¨ë“  ë¶„ì„ê¸°ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
        tasks = [
            self._phishing_analyzer.analyze_url(url),
            self._phishing_analyzer.analyze_content(url, html_content),
            self._malware_analyzer.analyze_html(html_content),
            self._privacy_analyzer.analyze_page(url, html_content),
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ìˆ˜ì§‘
        for result in results:
            if isinstance(result, Exception):
                logger.error("ë¶„ì„ê¸° ì˜¤ë¥˜: %s", result)
                continue
            if result is not None:
                if isinstance(result, list):
                    for detail in result:
                        report.add_detail(detail)
                else:
                    report.add_detail(result)

        # LLM í˜ì´ì§€ ì¢…í•© ë¶„ì„ (ì„ íƒì )
        if use_llm and self._llm_inference is not None:
            llm_detail = await self._analyze_page_with_llm(url, html_content)
            if llm_detail is not None:
                report.add_detail(llm_detail)

        report.recommendations = self._generate_recommendations(report)
        report.analysis_time_ms = (time.monotonic() - start_time) * 1000

        await self._set_cached(cache_key, report)

        logger.info(
            "í˜ì´ì§€ ë¶„ì„ ì™„ë£Œ: %s â†’ %s (ì ìˆ˜: %.2f, %.1fms)",
            url, report.overall_level.name,
            report.overall_score, report.analysis_time_ms,
        )
        return report

    # ============================
    # LLM ë¶„ì„ ë‚´ë¶€ ë©”ì„œë“œ
    # ============================

    async def _analyze_url_with_llm(self, url: str) -> Optional[ThreatDetail]:
        """LLMì„ ì‚¬ìš©í•œ URL ì‹¬ì¸µ ë¶„ì„"""
        try:
            from agent.utils.feature_extractor import URLFeatureExtractor
            extractor = URLFeatureExtractor()
            features = extractor.extract(url)

            prompt = PromptTemplates.URL_USER_PROMPT.format(
                url=url,
                domain=features.get("domain", ""),
                subdomain_count=features.get("subdomain_count", 0),
                url_length=features.get("length", 0),
                special_char_ratio=features.get("special_char_ratio", 0.0),
                uses_ip=features.get("is_ip_address", False),
                is_https=features.get("is_https", False),
                entropy=features.get("entropy", 0.0),
            )

            response = await self._llm_inference.generate(
                system_prompt=PromptTemplates.URL_SYSTEM_PROMPT,
                user_prompt=prompt,
            )

            return self._parse_llm_threat_response(response, ThreatType.PHISHING)
        except Exception as e:
            logger.error("LLM URL ë¶„ì„ ì‹¤íŒ¨: %s", e)
            return None

    async def _analyze_script_with_llm(self, code: str) -> Optional[ThreatDetail]:
        """LLMì„ ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ ì‹¬ì¸µ ë¶„ì„"""
        try:
            from agent.utils.feature_extractor import JSFeatureExtractor
            extractor = JSFeatureExtractor()
            features = extractor.extract(code)

            # ì½”ë“œê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì „ì†¡
            code_snippet = code[:4000] if len(code) > 4000 else code

            prompt = PromptTemplates.SCRIPT_USER_PROMPT.format(
                code=code_snippet,
                eval_count=features.get("eval_count", 0),
                doc_write_count=features.get("document_write_count", 0),
                encoded_string_count=features.get("encoded_string_count", 0),
                var_entropy=features.get("variable_name_entropy", 0.0),
                obfuscation_score=features.get("obfuscation_score", 0.0),
            )

            response = await self._llm_inference.generate(
                system_prompt=PromptTemplates.SCRIPT_SYSTEM_PROMPT,
                user_prompt=prompt,
            )

            return self._parse_llm_threat_response(response, ThreatType.MALWARE)
        except Exception as e:
            logger.error("LLM ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ ì‹¤íŒ¨: %s", e)
            return None

    async def _analyze_page_with_llm(
        self, url: str, html_content: str
    ) -> Optional[ThreatDetail]:
        """LLMì„ ì‚¬ìš©í•œ í˜ì´ì§€ ì¢…í•© ì‹¬ì¸µ ë¶„ì„"""
        try:
            from agent.utils.feature_extractor import DOMFeatureExtractor
            extractor = DOMFeatureExtractor()
            features = extractor.extract(html_content)

            html_snippet = html_content[:2000] if len(html_content) > 2000 else html_content

            prompt = PromptTemplates.PAGE_USER_PROMPT.format(
                url=url,
                title=features.get("title", ""),
                form_count=features.get("form_count", 0),
                password_field_count=features.get("password_field_count", 0),
                external_script_count=features.get("external_script_count", 0),
                external_resource_ratio=features.get("external_resource_ratio", 0.0),
                iframe_count=features.get("iframe_count", 0),
                hidden_element_count=features.get("hidden_element_count", 0),
                html_snippet=html_snippet,
            )

            response = await self._llm_inference.generate(
                system_prompt=PromptTemplates.PAGE_SYSTEM_PROMPT,
                user_prompt=prompt,
            )

            return self._parse_llm_threat_response(response, ThreatType.PHISHING)
        except Exception as e:
            logger.error("LLM í˜ì´ì§€ ë¶„ì„ ì‹¤íŒ¨: %s", e)
            return None

    # ============================
    # LLM ì‘ë‹µ íŒŒì‹±
    # ============================

    def _parse_llm_threat_response(
        self, response: dict[str, Any], default_type: ThreatType
    ) -> Optional[ThreatDetail]:
        """
        LLM JSON ì‘ë‹µì„ ThreatDetailë¡œ ë³€í™˜

        Args:
            response: LLMì´ ë°˜í™˜í•œ íŒŒì‹±ëœ JSON
            default_type: ê¸°ë³¸ ìœ„í˜‘ ìœ í˜•

        Returns:
            ThreatDetail ë˜ëŠ” None (ì•ˆì „í•œ ê²½ìš°)
        """
        if not response:
            return None

        # ìœ„í˜‘ ìˆ˜ì¤€ íŒŒì‹±
        level_str = response.get("threat_level", "SAFE").upper()
        level_map = {
            "SAFE": ThreatLevel.SAFE,
            "LOW": ThreatLevel.LOW,
            "MEDIUM": ThreatLevel.MEDIUM,
            "HIGH": ThreatLevel.HIGH,
            "CRITICAL": ThreatLevel.CRITICAL,
        }
        threat_level = level_map.get(level_str, ThreatLevel.SAFE)

        # SAFEì´ë©´ None ë°˜í™˜
        if threat_level == ThreatLevel.SAFE:
            return None

        confidence = float(response.get("confidence", 0.5))
        confidence = max(0.0, min(1.0, confidence))

        # ìœ„í˜‘ ìœ í˜• ê²°ì •
        threat_types = response.get("threat_types", [])
        if threat_types:
            type_map = {
                "phishing": ThreatType.PHISHING,
                "malware": ThreatType.MALWARE,
                "xss": ThreatType.XSS,
                "privacy": ThreatType.PRIVACY,
                "cert": ThreatType.CERT,
            }
            actual_type = type_map.get(threat_types[0], default_type)
        else:
            actual_type = default_type

        return ThreatDetail(
            threat_type=actual_type,
            threat_level=threat_level,
            confidence=confidence,
            description=response.get("reasoning", "LLM ë¶„ì„ ê²°ê³¼"),
            indicators=response.get("indicators", response.get("suspicious_patterns", [])),
            metadata={
                "source": "llm",
                "recommendation": response.get("recommendation", ""),
                "behavior_prediction": response.get("behavior_prediction", ""),
            },
        )

    # ============================
    # ê¶Œì¥ ì‚¬í•­ ìƒì„±
    # ============================

    def _generate_recommendations(self, report: ThreatReport) -> list[str]:
        """ìœ„í˜‘ ë³´ê³ ì„œ ê¸°ë°˜ ê¶Œì¥ ì‚¬í•­ ìƒì„±"""
        recommendations: list[str] = []

        if report.overall_level == ThreatLevel.SAFE:
            recommendations.append("ì´ í˜ì´ì§€ëŠ” ì•ˆì „í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
            return recommendations

        # ìœ„í˜‘ ìœ í˜•ë³„ ê¶Œì¥ ì‚¬í•­
        threat_types_found = {d.threat_type for d in report.details}

        if ThreatType.PHISHING in threat_types_found:
            recommendations.append(
                "âš ï¸ í”¼ì‹± ì˜ì‹¬: ì´ ì‚¬ì´íŠ¸ì— ê°œì¸ ì •ë³´ë¥¼ ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”."
            )
            recommendations.append(
                "URLì„ ì£¼ì˜ ê¹Šê²Œ í™•ì¸í•˜ê³ , ê³µì‹ ì‚¬ì´íŠ¸ ì£¼ì†Œì™€ ë¹„êµí•˜ì„¸ìš”."
            )

        if ThreatType.MALWARE in threat_types_found:
            recommendations.append(
                "ğŸš¨ ì•…ì„±ì½”ë“œ ì˜ì‹¬: ì´ í˜ì´ì§€ì˜ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì§€ ë§ˆì„¸ìš”."
            )
            recommendations.append(
                "JavaScript ì‹¤í–‰ì´ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )

        if ThreatType.XSS in threat_types_found:
            recommendations.append(
                "âš¡ XSS ì·¨ì•½ì  íƒì§€: ì´ í˜ì´ì§€ì—ì„œ ì…ë ¥í•œ ë°ì´í„°ê°€ ìœ ì¶œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )

        if ThreatType.PRIVACY in threat_types_found:
            recommendations.append(
                "ğŸ‘ï¸ í”„ë¼ì´ë²„ì‹œ ìœ„í˜‘: ì¶”ì ê¸°ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. "
                "ì¶”ì  ì°¨ë‹¨ ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ì„¸ìš”."
            )

        # ì‹¬ê°ë„ë³„ ì¶”ê°€ ê¶Œì¥ ì‚¬í•­
        if report.overall_level >= ThreatLevel.HIGH:
            recommendations.append(
                "ğŸ›‘ ë†’ì€ ìœ„í˜‘ ìˆ˜ì¤€: ì´ ì‚¬ì´íŠ¸ë¥¼ ì¦‰ì‹œ ë– ë‚˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
        elif report.overall_level >= ThreatLevel.MEDIUM:
            recommendations.append(
                "âš ï¸ ì¤‘ê°„ ìœ„í˜‘ ìˆ˜ì¤€: ì£¼ì˜í•˜ì—¬ ì´ìš©í•˜ì„¸ìš”."
            )

        return recommendations

    # ============================
    # ìºì‹œ ê´€ë¦¬
    # ============================

    def _make_cache_key(self, prefix: str, value: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        return f"{prefix}:{hashlib.md5(value.encode()).hexdigest()}"

    async def _get_cached(self, key: str) -> Optional[ThreatReport]:
        """ìºì‹œì—ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if not self.config.llm.cache_enabled:
            return None

        async with self._cache_lock:
            entry = self._cache.get(key)
            if entry is None:
                return None
            if entry.is_expired:
                del self._cache[key]
                return None
            # ìºì‹œ íˆíŠ¸ í‘œì‹œ
            report = entry.report
            report.cached = True
            return report

    async def _set_cached(self, key: str, report: ThreatReport) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥"""
        if not self.config.llm.cache_enabled:
            return

        async with self._cache_lock:
            # ìºì‹œ í¬ê¸° ì œí•œ í™•ì¸
            if len(self._cache) >= self.config.llm.cache_max_size:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (ê°„ë‹¨í•œ FIFO)
                oldest_key = next(iter(self._cache))
                del self._cache[oldest_key]

            self._cache[key] = _CacheEntry(
                report=report,
                created_at=time.time(),
                ttl=float(self.config.llm.cache_ttl_seconds),
            )

    async def clear_cache(self) -> None:
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        async with self._cache_lock:
            self._cache.clear()
            logger.info("ë¶„ì„ ê²°ê³¼ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

    @property
    def cache_size(self) -> int:
        """í˜„ì¬ ìºì‹œ í•­ëª© ìˆ˜"""
        return len(self._cache)

    # ============================
    # ìœ í‹¸ë¦¬í‹°
    # ============================

    def _ensure_initialized(self) -> None:
        """ì´ˆê¸°í™” ì—¬ë¶€ í™•ì¸"""
        if not self._initialized:
            raise RuntimeError(
                "SecurityAgentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "await agent.initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            )

    @property
    def is_initialized(self) -> bool:
        """ì´ˆê¸°í™” ìƒíƒœ"""
        return self._initialized

    def __repr__(self) -> str:
        return (
            f"SecurityAgent(name={self.config.agent_name!r}, "
            f"version={self.config.version!r}, "
            f"initialized={self._initialized})"
        )
